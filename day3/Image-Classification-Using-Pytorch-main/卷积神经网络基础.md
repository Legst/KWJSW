# 卷积神经网络（Convolutional Neural Network, CNN）基础

卷积神经网络是一类专门用于处理具有网格结构数据（如图像）的深度学习模型，广泛应用于计算机视觉、图像识别、目标检测等领域。

---

## 1. CNN 结构组成

### 1.1 输入层
- 接收原始数据，如图像的像素矩阵。

### 1.2 卷积层（Convolutional Layer）
- 通过卷积核（滤波器）对输入进行局部感受野的特征提取。
- 每个卷积核提取不同的特征（如边缘、纹理等）。
- 公式示例：

\[
Y(i,j) = \sum_m \sum_n X(i+m, j+n) \times W(m,n)
\]

其中，\(X\) 是输入，\(W\) 是卷积核。

### 1.3 激活层（Activation Layer）
- 常用ReLU激活函数，增强模型非线性能力。

```python
def relu(x):
    return max(0, x)
```
1.4 池化层（Pooling Layer）
下采样，降低空间尺寸，减少参数量，防止过拟合。

常用最大池化（Max Pooling）：


# 2x2最大池化示例

```python
输入矩阵：
[[1, 3],
 [2, 4]]
输出为4（局部最大值）
```

```python
import torch
import torchvision
from torch import nn
from torch.nn import MaxPool2d
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
#
dataset = torchvision.datasets.CIFAR10(root="./dataset_chen",
                                       train=False,
                                       transform=torchvision.transforms.ToTensor(),
                                       download=True)
dataloader = DataLoader(dataset=dataset,
                        batch_size=64)

# # 最大池化没法对long整形进行池化
# input = torch.tensor([[1,2,0,3,1],
#                       [0,1,2,3,1],
#                       [1,2,1,0,0],
#                       [5,2,3,1,1],
#                       [2,1,0,1,1]], dtype = torch.float)
# input =torch.reshape(input,(-1,1,5,5))
# print(input.shape)


class Chen(nn.Module):
    def __init__(self):
        super().__init__()
        self.maxpool_1 = MaxPool2d(kernel_size=3,
                                   ceil_mode=False)
    def forward(self,input):
        output = self.maxpool_1(input)
        return output

chen = Chen()

writer = SummaryWriter("maxpool_logs")
step = 0
for data in dataloader:
    imgs, targets = data
    writer.add_images("input",imgs,step)
    output = chen(imgs)
    writer.add_images("ouput",output,step)
    step += 1
writer.close()

#
# output = chen(input)
# print(output)
```

### 1.5 全连接层（Fully Connected Layer）
将卷积层和池化层提取的特征映射转换为最终的分类结果。

## 2. CNN 的基本流程
输入图像（如28x28灰度图像）

多个卷积层 + 激活函数提取特征

池化层减少特征图尺寸

展平（Flatten）特征图

全连接层进行分类

输出预测结果

## 3. 代码示例（使用 PyTorch）

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # 输入1通道，输出6通道，卷积核大小5x5
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(6 * 12 * 12, 10)  # 10分类输出

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # 卷积+激活+池化
        x = x.view(-1, 6 * 12 * 12)           # 展平
        x = self.fc1(x)                       # 全连接层
        return x
```

## 4. 学习笔记
卷积层的作用是提取局部空间特征。

池化层降低特征图大小，提高计算效率。

ReLU 激活函数常用于引入非线性。

多层卷积和池化可以提取越来越复杂的特征。

全连接层通常作为分类器使用。

训练过程中使用反向传播和梯度下降优化网络权重。

CNN 是深度学习中非常核心的模型，多多练习代码实现和调试，会更好理解其工作原理。

